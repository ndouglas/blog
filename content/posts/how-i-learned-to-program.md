---
title: "How I Learned to Program"
date: 2021-11-25T11:31:07-05:00
draft: false
---
Inspired by Dan Luu's [post](https://danluu.com/learning-to-program/)...

To explain my programming career, I'd like to tell you a true story about how I joined my high school marching band.

As a junior, I signed up for the class, not being able to read or play music (I played guitar, but very poorly).  Mostly because I needed more credit hours, due to the number of classes I'd failed.

The band director didn't know what to do with me; he certainly didn't have enough time to teach me to play an instrument.

He asked me what I wanted to play.  I suggested tenor saxophone, because -- well, I have no idea.  He gave me a tuba and sent me to a practice room, where I stayed for the rest of the semester, alternating between boredom, frustration, panic, and actually trying to get a sound out of my instrument.

I came out at the end of the semester knowing roughly what I knew at the beginning.

So this is a story about the importance of mentoring, guidance, support, and resources, and structure.  Because, as it turns out, I do _really, really badly_ without those things.

## The Early Years (1980-1993)

I'm 41 this year, and when I was a kid in the mid-eighties computers were rare devices.  I was a poor kid in Eastern Kentucky and no one there had a computer.  I got to play _Pitfall_ on an Atari when I was maybe four or five.  Once, around that time, I was walking through my grandparents' house and my aunt and uncle, who were comparatively well-off, were visiting, and one of them had brought their computer.  It sat on the dining room table, switched off, and I had an intense curiosity about it.  I knew that it was a computer (to be honest, it might've been a word processor), but I don't really know how I knew, or what that signified.  I was drawn to it.  But I wasn't allowed to even touch it.

I was in the second grade, now in Twin Lakes, New Mexico, when I first went to the school computer lab.  One time, I couldn't tear myself away -- from _Number Munchers_, mind you -- and pissed my pants.  My third grade classroom (this was in Springerville, Arizona; we moved around a bit) had an Atari computer.  I mostly remember games like _Pharoah's Curse_ and _Preppie II_.

In fourth and fifth grade (back to New Mexico; this time, Gallup), I was introduced to further offerings from those titans of '80's educational software, MECC, home of _The Oregon Trail_, the storied _Munchers_ franchise, _Miner's Cave_, etc.

Now, this is a post about learning to program, and up until now I haven't written one instruction of any kind.  I think we might've typed out a brief paper in one class in fourth or fifth grade.  It seems to me now, looking back, that the educators knew computers were important, but they didn't really know _why_ or _how_.  So computers were glorified, somewhat quieter typewriters that could also play video games.

## QBasic and Other Failures (1993-1999)

Up until the fifth grade or so, school (and life) seemed pretty straightforward.  But in October of 1991, my father passed away suddenly and unexpectedly, and my mother sank into a deep depression.  I felt emotionally abandoned, my home life became completely disorganized, and as I lived over an hour away from my school, I had no real extra-curricular relationships with other kids.  I had books, I had walks, and I had my imagination.  And I had, although I didn't know it, severe ADHD.

In seventh grade, the computer lab elective was a full semester.  And we had an actual computer _teacher_, a man named Mr. Laman, a tall cyclist dude who looked vaguely like a cross between Steve Jobs and Where's Waldo but was generally pretty cool.  There was a lot of typing, but we also learned QBasic.  Sort of.  We learned `for` loops, drawing lines and circles, that sort of thing -- but interestingly, no subroutines, no different number types, no booleans, that sort of thing.  We just didn't structure the code; control flowed straight through.  I wanted to do more, and I read the QBasic help pages, but they were technical help and not geared at kids learning to program in general.  I remember clearly reading their documentation about integers and not really understanding what an integer was, let alone a signed or unsigned integer, or knowing why one would go from 0 to 65535 and the other from -32766 to 32767.

I'm sure many people have learned to program from such documentation, or worse.  I didn't.

In 1994 or so, after years of begging, my mother purchased a Packard Bell 486 with 4MB RAM and a 426MB hard drive.  It was a low-end machine already, I think, but I could play some games on it -- and it had QBasic, although I still didn't make it very far there.  My programming during this time was basically limited to fiddling around with [TADS](https://www.tads.org/index.htm) and [Inform](http://inform7.com/), mixing my interest in writing with my interest in computers.

So, basically, I was in a situation where I had no real family educational support and my school was not outstanding.  I just didn't really get anywhere.  There were libraries, but the one in my town had no books about computer programming.  There were bookstores, but my mother never bought books new – she couldn't afford it – and the used bookstores never seemed to have any computer books.  And I didn't know what to buy anyway.  The WWW wasn't a thing yet, so I couldn't search online for beginner books.  I knew vaguely that there were different programming languages with names like C and C++, but my friend told me that Borland's compiler cost a lot of money.

These obstacles can seem trivial, especially nowadays.  But how could I learn if nobody around me seemed to know anything, if I could never find any books or other resources, if I didn't even know what books I needed to read, or what questions to ask to find books to read, or even how to find people I could ask those questions?

Ultimately, I learned very, very little.  When Windows 95 came out, I couldn't use it because my computer didn't meet the requirements.  I had that first, increasingly obsolete computer until February of 1999.

## I Meet Linux (1999-2005)

My house burned down in February 1999.  Presumably the rules of changed now, but at the time computers depreciated as slowly as any other household item.  Coupled with the decreasing costs of hardware, I could get a reasonable new computer with the insurance payout for the old one.  It was an AMD K6-2 333MHz with 96MB of RAM and a 4GB hard drive.  And Windows 98, which I liked at first but quickly came to dislike.

I went off to college (my GPA had remained atrocious, about a 1.667, but I did a couple of semesters of penance at a community college and managed to get accepted at a state college).  I purchased a Red Hat boxed set and installed Linux.

It was a difficult experience.  I actually ended up switching back and forth between Windows and Linux several times that semester; I would get frustrated by my inability to understand WTF was happening in Linux and switch back to Windows, but then the 1337ness and general appeal of Linux would pull me back.

When I _did_ manage to get some use out of Linux, it didn't last terribly long.  For one, Red Hat asked me if I wanted to create a separate partition for `/home`, for `/boot`, `/usr`, `/var`, `/usr/local`, etc etc etc etc, and being a dumbass, I did.  So I'd frequently end up formatting and reinstalling because I'd given like 256MB to `/usr/local` or 768MB to `/home` and then would find out quickly that just wasn't enough.

In this time, I dropped out of college, joined the Navy, left the Navy, went back to college, switched colleges, met my (now) wife, etc.  I used computers for chat, the occasional NES emulator, and web browsing, and little more.  Sometimes I had Linux installed, sometimes Windows.  I learned a decent amount -- the knowledge that comes from making mistakes, from running headlong into a wall, backing up, turning, and running headlong into another.  It's a stupid, frustrating, painful way to learn.

When I did run Linux, in the 2002-2005 timespan, it was Gentoo.  Gentoo taught me a lot.  The most important thing that it taught me was that I could not get anything done running Gentoo -- I spent far too much time compiling, recompiling, optimizing, breaking my system, resetting, rebuilding, etc.  I'd come to really like Linux, but I wanted something simpler, something that Just Worked™, something that would literally not let me spend all day configuring it.

## I Meet Mac (2005-2009)

My first Mac was really where I got started actually programming.  I'd started writing at some point, working on an idea I was sure would fill up an entire series of novels and be the most complex thing ever written.  And of course, if you're going to write such a thing, you need to plan it.  And you can't plan such a thing with mere paper or TextEdit.  You need something serious, like... like... MediaWiki.

MediaWiki?

Yes, MediaWiki.

My idea was to plan out this series of novels using a Wiki.  Countless fandoms now have wikis, but at the time this was kind of uncommon.  Wikipedia was new-ish, TVTropes was in its infancy, and I finally got into "real" programming (with functions!) with PHP, making little modifications and patches on my local MediaWiki.

MediaWiki was how I finally learned about web servers, DBMS (or at least MySQL), and some system administration stuff.  Painfully, because that's the only way I seemed to be able to learn anything.

When I got too frustrated with the relative slowness of editing a MediaWiki hosted on a laptop, I would experiment with Objective-C.  Apple provided Xcode for free, and Xcode wanted you to use Objective-C, and I could spin up a very simple app from a template, which seemed kind of cool.  I could move a button, recompile, and the button was moved.  Awesome.  I had no idea how any of that worked, so I just stayed with the line-level stuff, which I could at least understand.  I would get compiler errors, or... I wouldn't.  I could insert logging statements and be able to see _something_ of what was happening.

But more than anything else, I was deeply fascinated by the features of Objective-C as a language.  Object-oriented programming and message passing deeply appealed to me.  I could understand and appreciate this concept of a program as a collection of objects passing messages to one another, even though I really struggled to understand it and struggled even more to actually get anything done.  I read a couple of books about programming and horribly misapplied them; I read the Gang of Four _Design Patterns_ book and promptly built an architecture utilizing every design pattern in some way.  And the code was awful, obviously.

Now, I was unemployed during all of this time.  I went to college, would drop out, go to another college, drop out from there, etc.  I had no money and debts were piling up.  I had no direction, no idea of what to do with my life.  I was deeply depressed.  I'd been trying to write my books for years, but it seemed like I was only getting further and further behind.  Each time I started over, with a new One True Plan™ for organizing my ideas, I got less accomplished.

So I decided to go back to school one last time.  Instead of going for something related to writing -- Creative Writing, Philosophy, or English -- I would go back for a marketable skill of some kind, so I could support myself and my wife and any kids we might have.  I was Growing Up.

It's hard to believe, but until this point I'd never considered majoring in Computer Science and being a programmer.  I don't think I thought it was attainable.  Indeed, I considered a number of alternatives -- being an electrician, a plumber, an architect.  But I psyched myself up and went back to school.

## Back to School (2009-2011)

Math classes damn near killed me.  I hadn't legitimately passed a math class since the 5th grade.  I'd done some stuff with math in the Navy, but it was a limited subset of algebra, and once I learned it and passed the test it went right back out to the ol' bit bucket.  I passed Calculus I on, I think, my fourth try.  I didn't know how to study.  I didn't know how to do homework.  I didn't know how to learn.

But Calc II I passed with a B on my first try.  I'd learned _something_.

I went to UNLV, not Stanford or Caltech or MIT, but my classes were good and I learned a lot.  The structure was just what I needed.  I breezed through the labs in my Comp Sci I class, since they were mostly just getting to know Linux.  As I recall, they were set up so that you could do the labs for the semester at your own pace; I think I did them all in one or two one-hour labs.  The class taught C++, though of course with a light touch, and suddenly I felt like I was _really_ programming and _really_ solving actual problems.  I wrote the code, I knew what the code was doing, and I compiled it, and it ran.  I was almost thirty, and finally doing what I'd wanted to do since I was twelve or so.

I won't bother recounting the rest of my time getting my bachelor's.  It was probably a pretty standard state school degree experience, with the difference being that I was an adult student.

## My First Programming Job (2012-2015)

I managed to get my first programming job while still going to school.  I finished school December of 2011 and started at my new employer in January of 2012.  They were the beloved developers of a software package I'd used enthusiastically to organize my writing for several years.  I was paid $4K a month during a three month probationary period, then $4500 after that for a couple of years.  By the time I left, I was making $60K a year.  I loved the company, loved the product, and felt like I was making a killing.

It was the absolute worst thing I could've done.

Despite my age (31), I was still very much a junior programmer.  I had no experience with actual application programming or longer-term projects.  I didn't have any non-trivial experience with modern IDEs except for Xcode (which I didn't understand) or development practices (like Git, etc).  I'd done some very, very limited programming homework involving `pthreads`.  I'd possibly written some JavaScript code that did some async stuff.

So at this job, I was initially assigned to make a little iOS web browser with some added features.  I thought it was going fairly well; I experimented with some different ways of debugging, some of which were good and most of which were awful.  I explored new technologies.  I learned how to read documentation, how to research and solve simple problems on my own.  It was going fine... for about a month and a half.

Our company was working on integrating sync technology into our flagship software product.  The app was powerful, frequently managing databases of tens of gigabytes and tens of thousands of files, which might be text files, images, large PDFS, or arbitrary files.  Synchronizing these files -- to another machine on the local network, to a WebDAV server, to a Box.com account, to Dropbox -- with any sort of speed and reliability -- would be a substantial development task.  One man was working on it -- a brilliant developer, to be clear -- but just one.  And the project was a couple of months overdue.  And then, after some increasingly acrimonious conference calls and progress reports, he announced that he was leaving the company.

And I was left to take over the project.

It was theoretically near completion.  But it crashed very frequently.  It used idioms I was largely unfamiliar with -- massive multithreading, a custom-coded promises library, some fairly complex I/O -- and had terrible issues with concurrency, memory safety, memory leaks, cancellation, error handling, etc.  I was completely unprepared for dealing with this on any level, and it became my full-time job.

I needed mentoring, patience, and companionship.  What I actually got was the tuba and the practice room.

We eventually brought it to market.  It worked... sort of.  I improved it... sort of.  It was never completely stable.  Someone requested encryption and I added it... a horribly broken implementation.  At some point, I fixed that, but it required everyone's remote stores to be completely rewritten.  It was not a good product.

So I pushed for abandoning it and replacing it with a successor that would be coded from scratch in a system I actually understood.  This new system could use automatic reference counting, which relieved a lot of the issues with memory management that plagued the existing system.  My idea was to actually perform replication using a NoSQL document database system, so my contribution would merely be a translating layer that would convert between the local document format and the document db format.  Seemed simple.

Also, we decided to add our own cloud storage system.  We contracted with a company from Russia to do the server.  They got it done within a couple of months.  The problem was that some of their performance tests failed with the system as implemented.  These performance tests covered areas of the server code that dealt with managing the integrity and consistency of the database.  So, rather than relax the thresholds or rewrite the code, they outsourced the responsibility for maintaining database integrity to the client application -- my app plugin -- which might be connecting over wifi or even a cellular data connection.

I ended up needing to redesign my code to accomodate this.  I'm fuzzy on the details now, having tried for years to banish it from my mind.  And I'm still absolutely baffled that this decision was made, and baffled further that my employers went along with it, over my (weak, muffled) protests.  But instead of taking responsibility for the integrity of my local system, I now had to take responsibility for the integrity of the remote systems as well.

To try to conclude this overly long story, I failed.  I eventually had something that sort of worked, but it took up a massive amount of memory, it ran too slowly, and it wasn't going to be able to guarantee the remote system's stability.  I was fired within a couple of days of demoing my work.

I was so disheartened and depressed by the whole experience that the job opening I was most excited about wasn't even a programming job.  It was for high-level tech support.  It would pay me $20,000 more than my programming job.  But they ultimately withdrew the offer because I lived in Mississippi at the time, and they didn't want to fill out the paperwork necessary to legally employ me.

When that offer fell through, I grew more persistent with my second preference, a news company that had been stalling on extending an offer for a couple of weeks.  Finally, they sent over an offer and I accepted.  I would now be a Drupal developer.

## My Second Programming/First DevOps Job (2016-2020)

Now, I hadn't actually had much experience with Drupal, but I had played with it some in the 2000's when I wasn't fighting with MediaWiki.

But, dejected and disappointed as I was, I _had_ actually gained some skills at my previous employer.  I'd learned several ways _not_ to write code, to structure classes, to architect and manage projects, and so forth.  I'd learned about automated testing, about profiling, debugging with breakpoints, and version control.  I learned slowly, and I learned painfully, but I learned.

And my new employer had fairly low expectations for me (as I later learned, I was not their first choice).  So, when I actually showed occasional signs of competence, it was a pleasant surprise for all involved.  I bounced around between a great many projects, and most of them did not even involve Drupal.  One week, I'd set up an FTP server.  The next week, I'd work on a Drupal view or custom module.  The week after that, I'd work on our Google Analytics code.

There were ups and downs, of course, and still a lot of blunders.  But they were smoothed out.  I came to appreciate my coworkers and their strengths, and vice versa.  It was wonderful.  It was not an agile workplace, but far more so than my first employer.  We frankly admitted our ignorance.  We were all convinced we were out of our depth.  And so we felt free to experiment, and explore, and learn.

We had major projects now and then -- redesign one website, build another from scratch, achieve GDPR compliance -- but mostly we just maintained Drupal, worked to improve the editorial experience, fixed issues as they arose, and learned.

I started branching out into DevOps around this time.  I'd always liked Linux, and I liked the idea of being able to orchestrate infrastructure, and so I started exploring things like Docker and AWS services in my free time.  I set up a Kubernetes cluster for my personal learning, although I found that it was overkill for the kinds of things that I wanted to do.

And when our hosting provider complained about our Solr usage, I spun up a new Solr server in AWS.  When we began planning our long-awaited migration to Drupal 8, I managed the testing, deployment, and all other infrastructure in AWS.  It was fun and educational and it seemed to work just as well as our hosting provider.

So, after a few years, my employer had enough confidence in me, and I had enough confidence in myself, to move our main Drupal sites off that hosting provider and into AWS.  And it went off without a hitch.

Our final large project together was developing a new decoupled Drupal site.  After some experimentation and some mistakes, we settled on a Drupal 8 backend, Next.js frontend, and JSON:API communication between the two.  Largely invisible, but equally important, was a large collection of Node Lambda functions that handled site registration, payment processing, communications, and so forth.  I was able to write extensive automated tests for all of the code and felt very confident that it would function as intended.  So far as I know, that has been the case.

But, frankly, I wanted more.  I wanted more of a challenge.  I wanted more knowledge.  I wanted to play at a higher level.  So on a lark, I applied for a job listing that caught my eye, and I got my third (and current) job, as a Software/DevOps engineer.

## My Current Programming/DevOps Job (2020-)

Honestly, it's been a rough ride.  We're fully Agile here, which was new to me.  My coworkers are all brilliant and most have more (and more substantial) experience than I do.  I've made some visible and painful mistakes.  And the nature of the job itself involves things like presentations that I find deeply uncomfortable and sometimes terrifying.  (It occurs to me that being fired after my first and only demo at my first job might've left a couple of deep wounds on my psyche, lol.)

But my employer believes in me, and my coworkers depend on me.  After a year with the company, I now feel comfortable enough to stretch my wings a bit and aim higher.

## Current Status

So, after having had this blog for a while, and after not having done much at all with it, I think I'm going to use this to track my studies.  I want to study mathematics, to get good at the things I never managed to learn in school.  I want to build a solid knowledge of how to solve problems, and how to prove my knowledge.  I want to explore algorithms -- how to analyze them, how to write them.  I want to really understand computer science, and software engineering.  I want to get good -- really good.

I've purchased a number of books, and I want to work through them on this very blog.  It's going to be a struggle, it's going to take forever, and honestly if I get anywhere at all with this project, it will be an absolute outlier among all of my projects, public, professional, and private.

Let's see how it goes.
